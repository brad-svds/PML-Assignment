<!DOCTYPE html>
<html>

  <head>
    <meta charset='utf-8'>
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <meta name="description" content="Pml-assignment : Assignment for Coursera Course">

    <link rel="stylesheet" type="text/css" media="screen" href="stylesheets/stylesheet.css">

    <title>Pml-assignment</title>
  </head>

  <body>

    <!-- HEADER -->
    <div id="header_wrap" class="outer">
        <header class="inner">
          <a id="forkme_banner" href="https://github.com/brad-svds/PML-Assignment">View on GitHub</a>

          <h1 id="project_title">Pml-assignment</h1>
          <h2 id="project_tagline">Assignment for Coursera Course</h2>

            <section id="downloads">
              <a class="zip_download_link" href="https://github.com/brad-svds/PML-Assignment/zipball/master">Download this project as a .zip file</a>
              <a class="tar_download_link" href="https://github.com/brad-svds/PML-Assignment/tarball/master">Download this project as a tar.gz file</a>
            </section>
        </header>
    </div>

    <!-- MAIN CONTENT -->
    <div id="main_content_wrap" class="outer">
      <section id="main_content" class="inner">
        <hr>

<p>title: "Practical Machine Lerning - Fitness Data"
author: "Brad Allen"
date: "February 12, 2016"</p>

<h2>
<a id="output-html_document" class="anchor" href="#output-html_document" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>output: html_document</h2>

<h1>
<a id="executive-summary" class="anchor" href="#executive-summary" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Executive Summary</h1>

<p>Using devices such as Jawbone Up, Nike FuelBand, and Fitbit it is now possible to collect a large amount of data about personal activity relatively inexpensively. These type of devices are part of the quantified self movement â€“ a group of enthusiasts who take measurements about themselves regularly to improve their health, to find patterns in their behavior, or because they are tech geeks. </p>

<p>Using a weight lifting exercise dataset from <a href="http://groupware.les.inf.puc-rio.br/har">http://groupware.les.inf.puc-rio.br/har</a>, this analysis attempts to predict the manner of activity (sitting, standing, walking, etc) using a variety of gyroscopes and acceleromters. Using Random Forest classification, we ultimately develop a model that has greater than 99% accuracy on a holdout set. </p>

<h1>
<a id="analysis" class="anchor" href="#analysis" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Analysis</h1>

<p>We begin the analysis with some exploratory measures to understand the shape and size of the data. We find that there are 19,622 observations of 160 variables many of which do not have information (read NAs). </p>

<p>Originally, I removed the rows with NAs (using complete.cases()), but that left me with 30 rows and 160 variables - it did not bring me any closer to making an inference. I then explored removing the columns with NAs. Doing some high-level analysis of the NAs, we can determine that there is no pattern of NAs relative to the object we are classifying (eg, distribution of NA between "classe" A, B, C, D, or E).</p>

<p>Stripping the dataset of the variables with NAs, we were left with 93 variables. I originally attempted to run a Random Forest on this dataset and was surprised to find that R would not do an analysis on a set with greater than 53 dimensions. I was hoping I could determine which variables were most important and call it a day. :) Generally speaking, Random Forests have great predictive ability and are useful if we are not required to explain the logic embedded in the decision tree. (For example, healthcare applications might care about the path taken to a conclusion.)</p>

<p>I played around a little with Principal Component Analysis (PCA, in the appendix) and realized I needed to build a correlation matrix to remove strongly associated dimensions and try to get below the 53 threshold. Correlation Matrices only work on numeric datasets, so I stripped the data again of its non-numeric dimensions. </p>

<pre lang="r1,"><code>library("caret")
library("rpart")
library("tree")
library("randomForest")
library("e1071")
library("ggplot2")
library("corrplot")
library("nFactors")
data &lt;- read.csv("pmtraining.csv", header = TRUE)
predictor &lt;- as.vector(data$classe)

data &lt;- data[, apply(data, 2, function(x) !any(is.na(x)))] 
# training_clean &lt;- training[complete.cases(training), ]
data &lt;- data[sapply(data, is.numeric)]
</code></pre>

<p>The Correlation Matrix can be found below. I tried to remove the labels for the different variables, but could not find the code online. If you have any thoughts or recommendations, I would greatly appreciate it! </p>

<p>I developed a lost of the variables that had correlations greater than 0.8 and removed them from the data. I then added back the "classe" column, which is what we are trying to classify. You will notice that I removed the first 4 columns. This is the Index ("X") and other Timestamp data. When I first did the analysis, I found that I perfectly predicted all variables (Accuracy = 1). It turns out that the "classe" variable is listed in the dataset (all As, then all Bs, etc) - and the Index was being used to predict outcomes! </p>

<pre lang="r2,"><code>matrix &lt;- cor(data)
corrplot(matrix, type="upper", order="hclust", tl.col="black", tl.srt=45, ann = FALSE)

list = findCorrelation(matrix, cutoff=0.8)
list = sort(list)
data = data[,-c(list)]
data = cbind(data, predictor)
colnames(data)[44] &lt;- "classe"
data &lt;- data[ , 5:44]
</code></pre>

<p>We now have the data prepared to do some analysis. We set aside 25% of the data for a holdout, and develop a Random Forest model on the training set. Using the model to predict "classe" variables in the test set, we find that we have a 99.51% accuracy, and that the "yaw_belt", "pitch_belt", and "pitch_forearm" variables are most important.</p>

<p>This was then used on the test set for the exercise and provided 20/20 correct.</p>

<pre lang="r3,"><code>
set.seed(1000)
inTrain = createDataPartition(data$classe, p = 3/4)[[1]]
training = data[ inTrain,]
testing = data[-inTrain,]

fol &lt;- formula(classe ~ .)
model2 &lt;- randomForest(fol, data = training)
modelresult2 &lt;- predict(model2, testing, type = "class")
confusionMatrix(testing$classe, modelresult2)
rfimp &lt;- varImp(model2, scale = TRUE)
rfimp
</code></pre>

<h1>
<a id="appendix" class="anchor" href="#appendix" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>APPENDIX</h1>

<p>In doing this exercise, I learned a bit about PCA. It creates new variables from the dimensions, combining them to try and give predictive power to the variance. This is a Scree plot, which determines that there are 13 characteristics or PCA values, that together provide most of the explanatory power necessary for this analysis. </p>

<pre lang="r4,"><code>#remove the one we want to predict
ev &lt;- eigen(cor(data[sapply(data, is.numeric)])) # get eigenvalues
ap &lt;- parallel(subject=nrow(data[sapply(data, is.numeric)]),var=ncol(data[sapply(data, is.numeric)]),
               rep=100,cent=.05)
nS &lt;- nScree(x=ev$values, aparallel=ap$eigen$qevpea)
plotnScree(nS)
</code></pre>
      </section>
    </div>

    <!-- FOOTER  -->
    <div id="footer_wrap" class="outer">
      <footer class="inner">
        <p class="copyright">Pml-assignment maintained by <a href="https://github.com/brad-svds">brad-svds</a></p>
        <p>Published with <a href="https://pages.github.com">GitHub Pages</a></p>
      </footer>
    </div>

    

  </body>
</html>
